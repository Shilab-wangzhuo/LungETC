{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVS 图像切片工具 - 基于注释区域\n",
    "\n",
    "这个笔记本用于处理 SVS 格式的大型图像，只切割并保存包含注释区域的图像块。\n",
    "\n",
    "## 功能特点\n",
    "- 批量处理指定目录下的所有 SVS 文件\n",
    "- 自动查找对应的注释文件 (位于 `{sample_name}_kfb/Annotations/1.json`)\n",
    "- 只切割并保存与注释区域有重叠的图像块\n",
    "- 使用多线程加速处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# 设置 OpenCV 的最大像素限制，以处理大型图像\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2, 50).__str__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def find_svs_files(input_dir):\n",
    "    \"\"\"查找指定目录下所有的SVS文件\"\"\"\n",
    "    Info_list = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".svs\"):\n",
    "                svs_file_path = os.path.join(root, file)\n",
    "                print(f\"找到SVS文件: {svs_file_path}\")\n",
    "                svs_path, svs_name = os.path.split(svs_file_path)\n",
    "                sample_name = os.path.splitext(svs_name)[0]\n",
    "                \n",
    "                # 构建注释文件路径\n",
    "                annotation_dir = os.path.join(os.path.dirname(svs_file_path), f\"{sample_name}_kfb\", \"Annotations\")\n",
    "                annotation_file = os.path.join(annotation_dir, \"1.json\")\n",
    "                \n",
    "                if os.path.exists(annotation_file):\n",
    "                    file_dict = {\n",
    "                        'name': sample_name, \n",
    "                        'svs_path': svs_file_path,\n",
    "                        'annotation_path': annotation_file\n",
    "                    }\n",
    "                    Info_list.append(file_dict)\n",
    "                else:\n",
    "                    print(f\"警告: 未找到对应的注释文件 {annotation_file}\")\n",
    "    \n",
    "    return Info_list\n",
    "\n",
    "def load_annotations(annotation_file):\n",
    "    \"\"\"加载注释文件\"\"\"\n",
    "    try:\n",
    "        with open(annotation_file, 'r', encoding='utf-8') as f:\n",
    "            annotations = json.load(f)\n",
    "        \n",
    "        regions = []\n",
    "        for anno in annotations:\n",
    "            if 'region' in anno:\n",
    "                regions.append({\n",
    "                    'x': int(anno['region']['x']),\n",
    "                    'y': int(anno['region']['y']),\n",
    "                    'width': int(anno['region']['width']),\n",
    "                    'height': int(anno['region']['height']),\n",
    "                    'name': anno['name']\n",
    "                })\n",
    "        \n",
    "        return regions\n",
    "    except Exception as e:\n",
    "        print(f\"加载注释文件时出错: {e}\")\n",
    "        return []\n",
    "\n",
    "def is_patch_overlapping_annotations(left, top, right, bottom, annotations):\n",
    "    \"\"\"检查图像块是否与任何注释区域重叠\"\"\"\n",
    "    for anno in annotations:\n",
    "        anno_left = anno['x']\n",
    "        anno_top = anno['y']\n",
    "        anno_right = anno['x'] + anno['width']\n",
    "        anno_bottom = anno['y'] + anno['height']\n",
    "        \n",
    "        # 检查是否有重叠\n",
    "        if not (right <= anno_left or left >= anno_right or bottom <= anno_top or top >= anno_bottom):\n",
    "            return True, anno['name']\n",
    "    \n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def process_chunk(slide, output_folder, tile_size, overlap_rate, chunk_row, chunk_col, \n",
    "                 chunk_rows, chunk_cols, annotations, sample_name):\n",
    "    \"\"\"处理一个区块的图像切片\"\"\"\n",
    "    height, width = slide.shape[:2]\n",
    "    overlap_pixels = int(tile_size * overlap_rate)\n",
    "    saved_patches = 0\n",
    "    \n",
    "    for row in range(chunk_row, chunk_row + chunk_rows):\n",
    "        for col in range(chunk_col, chunk_col + chunk_cols):\n",
    "            left = col * (tile_size - overlap_pixels)\n",
    "            top = row * (tile_size - overlap_pixels)\n",
    "            right = min(left + tile_size, width)\n",
    "            bottom = min(top + tile_size, height)\n",
    "            \n",
    "            # 检查这个patch是否与任何注释重叠\n",
    "            has_overlap, anno_name = is_patch_overlapping_annotations(left, top, right, bottom, annotations)\n",
    "            \n",
    "            if has_overlap:\n",
    "                patch = slide[top:bottom, left:right]\n",
    "                # 使用样本名称和注释名称作为文件名的一部分\n",
    "                output_filename = f'{sample_name}_{anno_name}_tile_{row}_{col}.png'\n",
    "                output_path = os.path.join(output_folder, output_filename)\n",
    "                cv2.imwrite(output_path, patch)\n",
    "                saved_patches += 1\n",
    "    \n",
    "    return saved_patches\n",
    "\n",
    "def split_large_image_with_annotations(input_image_path, annotation_file, output_folder, \n",
    "                                      tile_size, overlap_rate, sample_name, chunk_size=50):\n",
    "    \"\"\"根据注释信息切割大图像\"\"\"\n",
    "    # 加载注释\n",
    "    annotations = load_annotations(annotation_file)\n",
    "    if not annotations:\n",
    "        print(f\"警告: 没有找到有效的注释信息 {annotation_file}\")\n",
    "        return 0\n",
    "    \n",
    "    print(f\"加载了 {len(annotations)} 个注释区域\")\n",
    "    \n",
    "    # 显示注释信息\n",
    "    display(HTML(\"<h4>注释区域信息:</h4>\"))\n",
    "    for i, anno in enumerate(annotations):\n",
    "        print(f\"注释 {i+1}: {anno['name']} - 位置: ({anno['x']}, {anno['y']}), 大小: {anno['width']}x{anno['height']}\")\n",
    "    \n",
    "    # 加载图像\n",
    "    try:\n",
    "        slide = cv2.imread(input_image_path, cv2.IMREAD_UNCHANGED | cv2.IMREAD_LOAD_GDAL)\n",
    "        if slide is None:\n",
    "            print(f\"错误: 无法加载图像 {input_image_path}\")\n",
    "            return 0\n",
    "            \n",
    "        height, width = slide.shape[:2]\n",
    "        print(f\"图像尺寸: {width}x{height}\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载图像时出错 {input_image_path}: {e}\")\n",
    "        return 0\n",
    "    \n",
    "    overlap_pixels = int(tile_size * overlap_rate)\n",
    "    rows = (height - overlap_pixels) // (tile_size - overlap_pixels) + 1\n",
    "    cols = (width - overlap_pixels) // (tile_size - overlap_pixels) + 1\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    print(f\"开始处理图像: {sample_name}\")\n",
    "    print(f\"将分割成 {rows}x{cols} 个块，但只保存包含注释的块\")\n",
    "    \n",
    "    total_saved_patches = 0\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for chunk_row in range(0, rows, chunk_size):\n",
    "            for chunk_col in range(0, cols, chunk_size):\n",
    "                chunk_rows = min(chunk_size, rows - chunk_row)\n",
    "                chunk_cols = min(chunk_size, cols - chunk_col)\n",
    "                futures.append(executor.submit(\n",
    "                    process_chunk, \n",
    "                    slide, output_folder, tile_size, overlap_rate, \n",
    "                    chunk_row, chunk_col, chunk_rows, chunk_cols,\n",
    "                    annotations, sample_name\n",
    "                ))\n",
    "        \n",
    "        total_chunks = len(futures)\n",
    "        with tqdm(total=total_chunks, desc=f\"处理 {sample_name}\") as pbar:\n",
    "            for future in futures:\n",
    "                saved_patches = future.result()\n",
    "                total_saved_patches += saved_patches\n",
    "                pbar.update(1)\n",
    "    \n",
    "    return total_saved_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置参数\n",
    "\n",
    "在下面的单元格中设置输入和输出目录，以及其他参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 设置参数\n",
    "input_dir = \"\"  # 请填写包含SVS文件的目录路径\n",
    "output_dir = \"\"  # 请填写输出目录路径\n",
    "tile_size = 1024  # 输出图像块的大小\n",
    "overlap_rate = 0.05  # 图像块之间的重叠率\n",
    "\n",
    "# 如果您希望直接处理单个SVS文件和注释文件，可以设置以下变量\n",
    "# 若设置，将忽略input_dir参数\n",
    "single_svs_file = \"\"  # 单个SVS文件的路径，留空则使用input_dir\n",
    "single_annotation_file = \"\"  # 单个注释文件的路径，留空则自动查找"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行处理\n",
    "\n",
    "运行以下单元格开始处理图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 验证参数\n",
    "if not input_dir and not single_svs_file:\n",
    "    print(\"错误: 请设置输入目录或单个SVS文件路径\")\n",
    "elif not output_dir:\n",
    "    print(\"错误: 请设置输出目录路径\")\n",
    "else:\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 处理单个文件或批量处理\n",
    "    if single_svs_file:\n",
    "        Info_list = []\n",
    "        svs_path, svs_name = os.path.split(single_svs_file)\n",
    "        sample_name = os.path.splitext(svs_name)[0]\n",
    "        \n",
    "        if single_annotation_file:\n",
    "            annotation_file = single_annotation_file\n",
    "        else:\n",
    "            # 自动查找注释文件\n",
    "            annotation_dir = os.path.join(os.path.dirname(single_svs_file), f\"{sample_name}_kfb\", \"Annotations\")\n",
    "            annotation_file = os.path.join(annotation_dir, \"1.json\")\n",
    "        \n",
    "        if os.path.exists(annotation_file):\n",
    "            file_dict = {\n",
    "                'name': sample_name, \n",
    "                'svs_path': single_svs_file,\n",
    "                'annotation_path': annotation_file\n",
    "            }\n",
    "            Info_list.append(file_dict)\n",
    "        else:\n",
    "            print(f\"错误: 未找到注释文件 {annotation_file}\")\n",
    "    else:\n",
    "        # 查找所有SVS文件及其对应的注释\n",
    "        Info_list = find_svs_files(input_dir)\n",
    "    \n",
    "    if not Info_list:\n",
    "        print(\"未找到任何有效的SVS文件和对应的注释\")\n",
    "    else:\n",
    "        print(f\"找到 {len(Info_list)} 个SVS文件及其注释\")\n",
    "        \n",
    "        # 处理每个SVS文件\n",
    "        total_files = len(Info_list)\n",
    "        total_patches_saved = 0\n",
    "        \n",
    "        for i, sample in enumerate(Info_list):\n",
    "            print(f\"\\n处理文件 {i+1}/{total_files}: {sample['name']}\")\n",
    "            print(f\"SVS文件: {sample['svs_path']}\")\n",
    "            print(f\"注释文件: {sample['annotation_path']}\")\n",
    "            \n",
    "            sample_output_folder = os.path.join(output_dir, sample['name'])\n",
    "            os.makedirs(sample_output_folder, exist_ok=True)\n",
    "            \n",
    "            patches_saved = split_large_image_with_annotations(\n",
    "                sample['svs_path'], \n",
    "                sample['annotation_path'], \n",
    "                sample_output_folder, \n",
    "                tile_size, \n",
    "                overlap_rate,\n",
    "                sample['name']\n",
    "            )\n",
    "            \n",
    "            total_patches_saved += patches_saved\n",
    "            print(f\"完成处理 {sample['name']}, 保存了 {patches_saved} 个图像块\")\n",
    "        \n",
    "        print(f\"\\n所有处理完成! 总共保存了 {total_patches_saved} 个图像块\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化结果\n",
    "\n",
    "以下单元格可以用来查看保存的图像块示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def show_sample_patches(output_dir, max_samples=5):\n",
    "    \"\"\"显示保存的图像块示例\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"输出目录 {output_dir} 不存在\")\n",
    "        return\n",
    "    \n",
    "    # 查找所有保存的图像块\n",
    "    all_patches = []\n",
    "    for root, _, files in os.walk(output_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                all_patches.append(os.path.join(root, file))\n",
    "    \n",
    "    if not all_patches:\n",
    "        print(\"未找到任何保存的图像块\")\n",
    "        return\n",
    "    \n",
    "    # 随机选择一些示例\n",
    "    import random\n",
    "    samples = random.sample(all_patches, min(max_samples, len(all_patches)))\n",
    "    \n",
    "    # 显示示例\n",
    "    fig, axes = plt.subplots(1, len(samples), figsize=(15, 5))\n",
    "    if len(samples) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, sample_path in enumerate(samples):\n",
    "        img = cv2.imread(sample_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(os.path.basename(sample_path))\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 显示一些保存的图像块示例\n",
    "if output_dir:\n",
    "    show_sample_patches(output_dir, max_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "这个笔记本实现了以下功能：\n",
    "\n",
    "1. 加载SVS格式的大型图像\n",
    "2. 读取对应的JSON格式注释文件\n",
    "3. 只切割并保存包含注释区域的图像块\n",
    "4. 使用多线程加速处理\n",
    "5. 提供了可视化工具查看结果\n",
    "\n",
    "这种方法可以大大减少存储空间和后续处理的工作量，因为只保存了包含感兴趣区域的图像块。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}